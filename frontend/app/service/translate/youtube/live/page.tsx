"use client"

import { useState, useEffect, useRef, Suspense, useCallback } from "react"
import { useSearchParams } from "next/navigation"

// ì§€ì› ì–¸ì–´ ëª©ë¡
const LANGUAGES: Record<string, string> = {
  "ko": "í•œêµ­ì–´",
  "en": "English",
  "ja": "æ—¥æœ¬èª",
  "zh": "ä¸­æ–‡",
  "es": "EspaÃ±ol",
  "fr": "FranÃ§ais",
  "de": "Deutsch",
  "auto": "ìë™ ê°ì§€",
}

// AssemblyAI ì–¸ì–´ ì½”ë“œ ë§¤í•‘
const ASSEMBLYAI_LANGUAGES: Record<string, string> = {
  "ko": "ko",
  "en": "en",
  "ja": "ja",
  "zh": "zh",
  "es": "es",
  "fr": "fr",
  "de": "de",
  "auto": "en", // ìë™ ê°ì§€ëŠ” ì˜ì–´ë¡œ ê¸°ë³¸ ì„¤ì •
}

export default function YouTubeLivePage() {
  return (
    <Suspense fallback={<div className="min-h-screen bg-black flex items-center justify-center text-white">ë¡œë”© ì¤‘...</div>}>
      <YouTubeLivePageContent />
    </Suspense>
  )
}

function YouTubeLivePageContent() {
  const searchParams = useSearchParams()
  const videoId = searchParams.get("v")
  const sourceLang = searchParams.get("source") || "auto"
  const targetLang = searchParams.get("target") || "ko"
  
  const [isListening, setIsListening] = useState(false)
  const [currentTranscript, setCurrentTranscript] = useState("")
  const [lastUtterance, setLastUtterance] = useState<{ original: string; translated: string } | null>(null)
  const [error, setError] = useState<string | null>(null)
  const [isReady, setIsReady] = useState(false)
  const [connectionStatus, setConnectionStatus] = useState<string>("ëŒ€ê¸° ì¤‘")
  
  const websocketRef = useRef<WebSocket | null>(null)
  const mediaRecorderRef = useRef<MediaRecorder | null>(null)
  const streamRef = useRef<MediaStream | null>(null)

  // ë²ˆì—­ í•¨ìˆ˜
  const translateText = useCallback(async (text: string, from: string, to: string): Promise<string> => {
    if (from === to || to === "none") return text
    
    try {
      const response = await fetch(
        `https://translation.googleapis.com/language/translate/v2?key=${process.env.NEXT_PUBLIC_GOOGLE_API_KEY}`,
        {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({
            q: text,
            source: from === "auto" ? undefined : from,
            target: to,
            format: "text",
          }),
        }
      )
      
      const data = await response.json()
      return data.data?.translations?.[0]?.translatedText || text
    } catch {
      return text
    }
  }, [])

  // ë°œí™” ì²˜ë¦¬ (ë²ˆì—­ í¬í•¨)
  const processUtterance = useCallback(async (text: string) => {
    const srcLang = sourceLang === "auto" ? "en" : sourceLang
    let translated = ""
    
    try {
      if (targetLang !== "none" && targetLang !== srcLang) {
        translated = await translateText(text, srcLang, targetLang)
      }
    } catch (err) {
      console.error("ë²ˆì—­ ì‹¤íŒ¨:", err)
    }
    
    setLastUtterance({ original: text, translated })
  }, [sourceLang, targetLang, translateText])

  // AssemblyAI ì‹¤ì‹œê°„ í† í° ê°€ì ¸ì˜¤ê¸°
  const getRealtimeToken = async (): Promise<string | null> => {
    try {
      const response = await fetch("/api/assemblyai/realtime", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          language_code: ASSEMBLYAI_LANGUAGES[sourceLang] || "en",
        }),
      })
      
      const data = await response.json()
      console.log("[AssemblyAI] Token API response:", data)
      
      if (data.token) {
        return data.token
      }
      
      // ë” ìì„¸í•œ ì—ëŸ¬ ë©”ì‹œì§€
      const errorMsg = data.error || `í† í° ë°œê¸‰ ì‹¤íŒ¨ (${response.status})`
      setError(`AssemblyAI: ${errorMsg}`)
      throw new Error(errorMsg)
    } catch (err) {
      console.error("AssemblyAI í† í° ì˜¤ë¥˜:", err)
      return null
    }
  }

  // AssemblyAI WebSocket ì—°ê²° ë° ì‹œìŠ¤í…œ ì˜¤ë””ì˜¤ ìº¡ì²˜
  const startCapture = async () => {
    try {
      setError(null)
      setConnectionStatus("ì—°ê²° ì¤‘...")
      
      // 1. ì‹œìŠ¤í…œ ì˜¤ë””ì˜¤ ìº¡ì²˜ (í™”ë©´ ê³µìœ )
      const stream = await navigator.mediaDevices.getDisplayMedia({
        video: true,
        audio: {
          echoCancellation: false,
          noiseSuppression: false,
          autoGainControl: false,
          sampleRate: 16000,
        }
      })

      const audioTracks = stream.getAudioTracks()
      if (audioTracks.length === 0) {
        setError("âš ï¸ ì˜¤ë””ì˜¤ ê³µìœ ë¥¼ ì²´í¬í•´ì£¼ì„¸ìš”!\n\ní™”ë©´ ê³µìœ  ì‹œ 'íƒ­ ì˜¤ë””ì˜¤ë„ ê³µìœ 'ë¥¼ ì¼œì£¼ì„¸ìš”.")
        stream.getTracks().forEach(track => track.stop())
        setConnectionStatus("ëŒ€ê¸° ì¤‘")
        return
      }

      // ë¹„ë””ì˜¤ íŠ¸ë™ ì¤‘ì§€ (ì˜¤ë””ì˜¤ë§Œ í•„ìš”)
      stream.getVideoTracks().forEach(track => track.stop())
      streamRef.current = new MediaStream(audioTracks)
      
      console.log("[AssemblyAI] ì˜¤ë””ì˜¤ íŠ¸ë™ ìº¡ì²˜ ì„±ê³µ:", audioTracks[0].label)
      setConnectionStatus("í† í° ë°œê¸‰ ì¤‘...")

      // 2. AssemblyAI ì‹¤ì‹œê°„ í† í° ê°€ì ¸ì˜¤ê¸°
      const token = await getRealtimeToken()
      if (!token) {
        setError("AssemblyAI ì—°ê²° ì‹¤íŒ¨. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        stream.getTracks().forEach(track => track.stop())
        setConnectionStatus("ëŒ€ê¸° ì¤‘")
        return
      }

      console.log("[AssemblyAI] í† í° ë°œê¸‰ ì„±ê³µ")
      setConnectionStatus("WebSocket ì—°ê²° ì¤‘...")

      // 3. WebSocket ì—°ê²°
      const ws = new WebSocket(
        `wss://api.assemblyai.com/v2/realtime/ws?sample_rate=16000&token=${token}`
      )

      ws.onopen = () => {
        console.log("[AssemblyAI] WebSocket ì—°ê²°ë¨")
        setConnectionStatus("ì—°ê²°ë¨")
        setIsListening(true)
        setIsReady(true)

        // 4. MediaRecorderë¡œ ì˜¤ë””ì˜¤ ì²­í¬ ì „ì†¡
        const audioContext = new AudioContext({ sampleRate: 16000 })
        const source = audioContext.createMediaStreamSource(streamRef.current!)
        const processor = audioContext.createScriptProcessor(4096, 1, 1)

        source.connect(processor)
        processor.connect(audioContext.destination)

        processor.onaudioprocess = (e) => {
          if (ws.readyState === WebSocket.OPEN) {
            const inputData = e.inputBuffer.getChannelData(0)
            const pcmData = convertFloat32ToInt16(inputData)
            const base64Audio = arrayBufferToBase64(pcmData.buffer)
            ws.send(JSON.stringify({ audio_data: base64Audio }))
          }
        }
      }

      ws.onmessage = async (event) => {
        const data = JSON.parse(event.data)
        
        if (data.message_type === "PartialTranscript") {
          setCurrentTranscript(data.text || "")
        } else if (data.message_type === "FinalTranscript") {
          const text = data.text?.trim()
          if (text) {
            console.log("[AssemblyAI] ìµœì¢… ì¸ì‹:", text)
            setCurrentTranscript("")
            await processUtterance(text)
          }
        } else if (data.message_type === "SessionBegins") {
          console.log("[AssemblyAI] ì„¸ì…˜ ì‹œì‘:", data.session_id)
        }
      }

      ws.onerror = (err) => {
        console.error("[AssemblyAI] WebSocket ì˜¤ë¥˜:", err)
        setError("AssemblyAI ì—°ê²° ì˜¤ë¥˜")
        setConnectionStatus("ì˜¤ë¥˜")
      }

      ws.onclose = (event) => {
        console.log("[AssemblyAI] WebSocket ì¢…ë£Œ:", event.code, event.reason)
        setIsListening(false)
        setConnectionStatus("ì—°ê²° ì¢…ë£Œ")
      }

      websocketRef.current = ws

      // ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ ê°ì§€
      audioTracks[0].onended = () => {
        console.log("[AssemblyAI] ì˜¤ë””ì˜¤ íŠ¸ë™ ì¢…ë£Œ")
        stopCapture()
      }

    } catch (err) {
      console.error("[AssemblyAI] ìº¡ì²˜ ì˜¤ë¥˜:", err)
      if ((err as Error).name === "NotAllowedError") {
        setError("í™”ë©´ ê³µìœ ê°€ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
      } else {
        setError("ì‹œìŠ¤í…œ ì˜¤ë””ì˜¤ ìº¡ì²˜ ì‹¤íŒ¨: " + (err as Error).message)
      }
      setConnectionStatus("ëŒ€ê¸° ì¤‘")
    }
  }

  // Float32 to Int16 ë³€í™˜ (AssemblyAI PCM í˜•ì‹)
  const convertFloat32ToInt16 = (float32Array: Float32Array): Int16Array => {
    const int16Array = new Int16Array(float32Array.length)
    for (let i = 0; i < float32Array.length; i++) {
      const s = Math.max(-1, Math.min(1, float32Array[i]))
      int16Array[i] = s < 0 ? s * 0x8000 : s * 0x7FFF
    }
    return int16Array
  }

  // ArrayBuffer to Base64
  const arrayBufferToBase64 = (buffer: ArrayBuffer): string => {
    const bytes = new Uint8Array(buffer)
    let binary = ""
    for (let i = 0; i < bytes.byteLength; i++) {
      binary += String.fromCharCode(bytes[i])
    }
    return btoa(binary)
  }

  // ìº¡ì²˜ ì¤‘ì§€
  const stopCapture = () => {
    // WebSocket ì¢…ë£Œ
    if (websocketRef.current) {
      websocketRef.current.close()
      websocketRef.current = null
    }
    
    // MediaRecorder ì¤‘ì§€
    if (mediaRecorderRef.current) {
      mediaRecorderRef.current.stop()
      mediaRecorderRef.current = null
    }
    
    // ìŠ¤íŠ¸ë¦¼ ì¤‘ì§€
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop())
      streamRef.current = null
    }
    
    setIsListening(false)
    setIsReady(false)
    setConnectionStatus("ëŒ€ê¸° ì¤‘")
  }

  // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
  useEffect(() => {
    return () => {
      stopCapture()
    }
  }, [])

  // ìë™ ì‹œì‘ (í˜ì´ì§€ ë¡œë“œ ì‹œ)
  useEffect(() => {
    if (videoId) {
      // ì•½ê°„ì˜ ë”œë ˆì´ í›„ ìë™ ì‹œì‘
      const timer = setTimeout(() => {
        startCapture()
      }, 500)
      return () => clearTimeout(timer)
    }
  // eslint-disable-next-line react-hooks/exhaustive-deps
  }, [videoId])

  if (!videoId) {
    return (
      <div className="min-h-screen bg-black flex items-center justify-center text-white">
        <p>YouTube ë¹„ë””ì˜¤ IDê°€ í•„ìš”í•©ë‹ˆë‹¤.</p>
      </div>
    )
  }

  return (
    <div className="min-h-screen bg-black flex flex-col">
      {/* YouTube ì˜ìƒ - ì „ì²´ í™”ë©´ */}
      <div className="flex-1 relative">
        <iframe
          src={`https://www.youtube.com/embed/${videoId}?autoplay=1&rel=0`}
          className="absolute inset-0 w-full h-full"
          allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
          allowFullScreen
        />
      </div>

      {/* ìë§‰ ì˜¤ë²„ë ˆì´ - í•˜ë‹¨ ê³ ì • */}
      <div className="fixed bottom-0 left-0 right-0 z-50">
        {/* ìƒíƒœ í‘œì‹œ ë°” */}
        <div className="flex items-center justify-between px-4 py-2 bg-black/70">
          <div className="flex items-center gap-3">
            <span className="text-white text-sm font-medium">UniLang</span>
            {isListening ? (
              <span className="flex items-center gap-1 text-green-400 text-xs">
                <span className="w-2 h-2 bg-green-400 rounded-full animate-pulse" />
                ì‹¤ì‹œê°„ í†µì—­ ì¤‘ (AssemblyAI)
              </span>
            ) : (
              <span className="text-yellow-400 text-xs">{connectionStatus}</span>
            )}
          </div>
          <div className="flex items-center gap-2">
            <span className="text-slate-400 text-xs">
              {LANGUAGES[sourceLang] || sourceLang} â†’ {LANGUAGES[targetLang] || targetLang}
            </span>
            {!isReady && (
              <button
                onClick={startCapture}
                className="px-3 py-1 bg-green-500 hover:bg-green-600 text-white text-xs rounded-full transition-colors"
              >
                ğŸ§ ì‹œìŠ¤í…œ ì˜¤ë””ì˜¤ ìº¡ì²˜
              </button>
            )}
            {isReady && (
              <button
                onClick={stopCapture}
                className="px-3 py-1 bg-red-500 hover:bg-red-600 text-white text-xs rounded-full transition-colors"
              >
                ì¤‘ì§€
              </button>
            )}
          </div>
        </div>

        {/* ìë§‰ ì˜ì—­ */}
        <div className="px-4 py-3 bg-black/85 min-h-[80px]">
          {error ? (
            <p className="text-red-400 text-center text-sm">{error}</p>
          ) : (
            <>
              {/* í˜„ì¬ ì¸ì‹ ì¤‘ì¸ í…ìŠ¤íŠ¸ */}
              {currentTranscript && (
                <p className="text-yellow-300 text-center text-lg mb-2 opacity-70">
                  {currentTranscript}...
                </p>
              )}
              
              {/* ìµœì¢… ìë§‰ */}
              {lastUtterance ? (
                <div className="text-center space-y-1">
                  <p className="text-white text-xl font-medium drop-shadow-lg">
                    {lastUtterance.original}
                  </p>
                  {lastUtterance.translated && (
                    <p className="text-green-400 text-xl font-medium drop-shadow-lg">
                      {lastUtterance.translated}
                    </p>
                  )}
                </div>
              ) : (
                <p className="text-slate-400 text-center text-sm">
                  {isListening 
                    ? "ğŸ§ ì‹œìŠ¤í…œ ì˜¤ë””ì˜¤ ì¸ì‹ ì¤‘... YouTube ì˜ìƒì„ ì¬ìƒí•´ì£¼ì„¸ìš”" 
                    : connectionStatus === "ëŒ€ê¸° ì¤‘" 
                      ? "ìœ„ ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ì‹œìŠ¤í…œ ì˜¤ë””ì˜¤ ìº¡ì²˜ë¥¼ ì‹œì‘í•˜ì„¸ìš”"
                      : connectionStatus}
                </p>
              )}
            </>
          )}
        </div>
      </div>
    </div>
  )
}

