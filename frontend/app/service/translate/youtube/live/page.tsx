"use client"

import { useState, useEffect, useRef, Suspense, useCallback } from "react"
import { useSearchParams, useRouter } from "next/navigation"
import { createClient } from "@/lib/supabase/client"

// ì§€ì› ì–¸ì–´ ëª©ë¡
const LANGUAGES: Record<string, string> = {
  "ko": "í•œêµ­ì–´",
  "en": "English",
  "ja": "æ—¥æœ¬èª",
  "zh": "ä¸­æ–‡",
  "es": "EspaÃ±ol",
  "fr": "FranÃ§ais",
  "de": "Deutsch",
  "auto": "ìë™ ê°ì§€",
}

// Deepgram ì–¸ì–´ ì½”ë“œ ë§¤í•‘
const DEEPGRAM_LANGUAGES: Record<string, string> = {
  "ko": "ko",
  "en": "en",
  "ja": "ja",
  "zh": "zh",
  "es": "es",
  "fr": "fr",
  "de": "de",
  "auto": "en",
}

interface Utterance {
  id: string
  original: string
  translated: string
  timestamp: Date
}

export default function YouTubeLivePage() {
  return (
    <Suspense fallback={<div className="min-h-screen bg-black flex items-center justify-center text-white">ë¡œë”© ì¤‘...</div>}>
      <YouTubeLivePageContent />
    </Suspense>
  )
}

function YouTubeLivePageContent() {
  const searchParams = useSearchParams()
  const router = useRouter()
  const videoId = searchParams.get("v")
  const sourceLang = searchParams.get("source") || "auto"
  const targetLang = searchParams.get("target") || "ko"
  
  const [isListening, setIsListening] = useState(false)
  const [currentTranscript, setCurrentTranscript] = useState("")
  const [utterances, setUtterances] = useState<Utterance[]>([])
  const [error, setError] = useState<string | null>(null)
  const [isReady, setIsReady] = useState(false)
  const [connectionStatus, setConnectionStatus] = useState<string>("ëŒ€ê¸° ì¤‘")
  const [showInstructions, setShowInstructions] = useState(true)
  
  // AI ì¬ì²˜ë¦¬ ìƒíƒœ
  const [isReorganizing, setIsReorganizing] = useState(false)
  const [isSummarizing, setIsSummarizing] = useState(false)
  const [summary, setSummary] = useState("")
  const [showSummary, setShowSummary] = useState(false)
  
  // DB ì €ì¥ ìƒíƒœ
  const [sessionId, setSessionId] = useState<string | null>(null)
  const [isSaving, setIsSaving] = useState(false)
  
  const websocketRef = useRef<WebSocket | null>(null)
  const audioContextRef = useRef<AudioContext | null>(null)
  const streamRef = useRef<MediaStream | null>(null)
  const utterancesEndRef = useRef<HTMLDivElement>(null)
  
  const supabase = createClient()

  // ìë™ ìŠ¤í¬ë¡¤
  useEffect(() => {
    if (utterancesEndRef.current) {
      utterancesEndRef.current.scrollIntoView({ behavior: "smooth" })
    }
  }, [utterances])

  // ë²ˆì—­ í•¨ìˆ˜
  const translateText = useCallback(async (text: string, from: string, to: string): Promise<string> => {
    if (from === to || to === "none") return text
    
    try {
      const response = await fetch(
        `https://translation.googleapis.com/language/translate/v2?key=${process.env.NEXT_PUBLIC_GOOGLE_API_KEY}`,
        {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({
            q: text,
            source: from === "auto" ? undefined : from,
            target: to,
            format: "text",
          }),
        }
      )
      
      const data = await response.json()
      return data.data?.translations?.[0]?.translatedText || text
    } catch {
      return text
    }
  }, [])

  // ë°œí™” ì²˜ë¦¬ (ë²ˆì—­ í¬í•¨)
  const processUtterance = useCallback(async (text: string) => {
    const srcLang = sourceLang === "auto" ? "en" : sourceLang
    let translated = ""
    
    try {
      if (targetLang !== "none" && targetLang !== srcLang) {
        translated = await translateText(text, srcLang, targetLang)
      }
    } catch (err) {
      console.error("ë²ˆì—­ ì‹¤íŒ¨:", err)
    }
    
    const newUtterance: Utterance = {
      id: `${Date.now()}_${Math.random().toString(36).slice(2)}`,
      original: text,
      translated,
      timestamp: new Date(),
    }
    
    setUtterances(prev => [...prev, newUtterance])
  }, [sourceLang, targetLang, translateText])

  // Deepgram API í‚¤ ê°€ì ¸ì˜¤ê¸°
  const getDeepgramApiKey = async (): Promise<string | null> => {
    try {
      const response = await fetch("/api/deepgram/token", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
      })
      
      const data = await response.json()
      console.log("[Deepgram] Token API response:", data)
      
      if (data.apiKey) {
        return data.apiKey
      }
      
      const errorMsg = data.error || `API í‚¤ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨ (${response.status})`
      setError(`Deepgram: ${errorMsg}`)
      throw new Error(errorMsg)
    } catch (err) {
      console.error("Deepgram API í‚¤ ì˜¤ë¥˜:", err)
      return null
    }
  }

  // ì‹œìŠ¤í…œ ì˜¤ë””ì˜¤ ìº¡ì²˜ ì‹œì‘
  const startCapture = async () => {
    try {
      setError(null)
      setConnectionStatus("ì—°ê²° ì¤‘...")
      setShowInstructions(false)
      
      // 1. ì‹œìŠ¤í…œ ì˜¤ë””ì˜¤ ìº¡ì²˜ (í™”ë©´ ê³µìœ ) - í˜„ì¬ íƒ­ ìš°ì„ 
      const stream = await navigator.mediaDevices.getDisplayMedia({
        video: true,
        audio: {
          echoCancellation: false,
          noiseSuppression: false,
          autoGainControl: false,
        },
        // @ts-expect-error - Chrome specific options
        preferCurrentTab: true,
        selfBrowserSurface: "include",
      })

      const audioTracks = stream.getAudioTracks()
      if (audioTracks.length === 0) {
        setError("âš ï¸ ì˜¤ë””ì˜¤ ê³µìœ ë¥¼ ì²´í¬í•´ì£¼ì„¸ìš”!\n\ní™”ë©´ ê³µìœ  ì‹œ 'íƒ­ ì˜¤ë””ì˜¤ë„ ê³µìœ 'ë¥¼ ì¼œì£¼ì„¸ìš”.")
        stream.getTracks().forEach(track => track.stop())
        setConnectionStatus("ëŒ€ê¸° ì¤‘")
        return
      }

      // ë¹„ë””ì˜¤ íŠ¸ë™ ì¤‘ì§€ (ì˜¤ë””ì˜¤ë§Œ í•„ìš”)
      stream.getVideoTracks().forEach(track => track.stop())
      streamRef.current = new MediaStream(audioTracks)
      
      console.log("[Deepgram] ì˜¤ë””ì˜¤ íŠ¸ë™ ìº¡ì²˜ ì„±ê³µ:", audioTracks[0].label)
      setConnectionStatus("API ì—°ê²° ì¤‘...")

      // 2. Deepgram API í‚¤ ê°€ì ¸ì˜¤ê¸°
      const apiKey = await getDeepgramApiKey()
      if (!apiKey) {
        setError("Deepgram ì—°ê²° ì‹¤íŒ¨. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        stream.getTracks().forEach(track => track.stop())
        setConnectionStatus("ëŒ€ê¸° ì¤‘")
        return
      }

      console.log("[Deepgram] API í‚¤ ê°€ì ¸ì˜¤ê¸° ì„±ê³µ")
      setConnectionStatus("ìŒì„± ì¸ì‹ ì—°ê²° ì¤‘...")

      // 3. ì–¸ì–´ ì½”ë“œ ì„¤ì •
      const deepgramLang = DEEPGRAM_LANGUAGES[sourceLang] || "en"

      // 4. WebSocket ì—°ê²°
      const ws = new WebSocket(
        `wss://api.deepgram.com/v1/listen?encoding=linear16&sample_rate=16000&channels=1&model=nova-2&language=${deepgramLang}&punctuate=true&interim_results=true`,
        ["token", apiKey]
      )

      ws.onopen = () => {
        console.log("[Deepgram] WebSocket ì—°ê²°ë¨")
        setConnectionStatus("ì—°ê²°ë¨ âœ“")
        setIsListening(true)
        setIsReady(true)

        // 5. ì˜¤ë””ì˜¤ ë°ì´í„° ì „ì†¡
        const audioContext = new AudioContext({ sampleRate: 16000 })
        audioContextRef.current = audioContext
        const source = audioContext.createMediaStreamSource(streamRef.current!)
        const processor = audioContext.createScriptProcessor(4096, 1, 1)

        source.connect(processor)
        // í•˜ìš¸ë§ ë°©ì§€
        const gainNode = audioContext.createGain()
        gainNode.gain.value = 0
        processor.connect(gainNode)
        gainNode.connect(audioContext.destination)

        processor.onaudioprocess = (e) => {
          if (ws.readyState === WebSocket.OPEN) {
            const inputData = e.inputBuffer.getChannelData(0)
            const pcmData = convertFloat32ToInt16(inputData)
            ws.send(pcmData.buffer)
          }
        }
      }

      ws.onmessage = async (event) => {
        try {
          const data = JSON.parse(event.data)
          
          if (data.type === "Results" && data.channel?.alternatives?.[0]) {
            const transcript = data.channel.alternatives[0].transcript
            
            if (data.is_final && transcript?.trim()) {
              console.log("[Deepgram] ìµœì¢… ì¸ì‹:", transcript)
              setCurrentTranscript("")
              await processUtterance(transcript.trim())
            } else if (transcript) {
              setCurrentTranscript(transcript)
            }
          }
        } catch (err) {
          console.error("[Deepgram] ë©”ì‹œì§€ íŒŒì‹± ì˜¤ë¥˜:", err)
        }
      }

      ws.onerror = (err) => {
        console.error("[Deepgram] WebSocket ì˜¤ë¥˜:", err)
        setError("ìŒì„± ì¸ì‹ ì—°ê²° ì˜¤ë¥˜")
        setConnectionStatus("ì˜¤ë¥˜")
      }

      ws.onclose = (event) => {
        console.log("[Deepgram] WebSocket ì¢…ë£Œ:", event.code, event.reason)
        setIsListening(false)
        setConnectionStatus("ì—°ê²° ì¢…ë£Œ")
      }

      websocketRef.current = ws

      // ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ ê°ì§€
      audioTracks[0].onended = () => {
        console.log("[Deepgram] ì˜¤ë””ì˜¤ íŠ¸ë™ ì¢…ë£Œ")
        stopCapture()
      }

    } catch (err) {
      console.error("[Deepgram] ìº¡ì²˜ ì˜¤ë¥˜:", err)
      if ((err as Error).name === "NotAllowedError") {
        setError("í™”ë©´ ê³µìœ ê°€ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
      } else {
        setError("ì‹œìŠ¤í…œ ì˜¤ë””ì˜¤ ìº¡ì²˜ ì‹¤íŒ¨: " + (err as Error).message)
      }
      setConnectionStatus("ëŒ€ê¸° ì¤‘")
    }
  }

  // Float32 to Int16 ë³€í™˜
  const convertFloat32ToInt16 = (float32Array: Float32Array): Int16Array => {
    const int16Array = new Int16Array(float32Array.length)
    for (let i = 0; i < float32Array.length; i++) {
      const s = Math.max(-1, Math.min(1, float32Array[i]))
      int16Array[i] = s < 0 ? s * 0x8000 : s * 0x7FFF
    }
    return int16Array
  }

  // ìº¡ì²˜ ì¤‘ì§€
  const stopCapture = () => {
    if (websocketRef.current) {
      websocketRef.current.close()
      websocketRef.current = null
    }
    
    if (audioContextRef.current) {
      audioContextRef.current.close()
      audioContextRef.current = null
    }
    
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop())
      streamRef.current = null
    }
    
    setIsListening(false)
    setIsReady(false)
    setConnectionStatus("ëŒ€ê¸° ì¤‘")
  }

  // AI ì¬ì •ë¦¬
  const reorganizeWithAI = async () => {
    if (utterances.length === 0) {
      setError("ì¬ì •ë¦¬í•  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")
      return
    }
    
    setIsReorganizing(true)
    setError(null)
    
    try {
      const utteranceData = utterances.map((u, i) => ({
        id: i + 1,
        text: u.original,
        translated: u.translated,
      }))
      
      const response = await fetch("/api/gemini/reorganize", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          utterances: utteranceData,
          targetLanguage: sourceLang === "auto" ? "en" : sourceLang,
        }),
      })
      
      const result = await response.json()
      
      if (!result.success) {
        throw new Error(result.error || "AI ì¬ì •ë¦¬ ìš”ì²­ ì‹¤íŒ¨")
      }
      
      const reorganized = result.data as { merged_from: number[]; text: string }[]
      
      if (!Array.isArray(reorganized) || reorganized.length === 0) {
        throw new Error("AI ì‘ë‹µ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
      }
      
      // ì¬ì •ë¦¬ëœ ê²°ê³¼ë¡œ utterances ì—…ë°ì´íŠ¸
      const newUtterances: Utterance[] = []
      for (const item of reorganized) {
        let translated = item.text
        if (targetLang !== "none" && sourceLang !== targetLang) {
          const srcLang = sourceLang === "auto" ? "en" : sourceLang
          translated = await translateText(item.text, srcLang, targetLang)
        }
        
        newUtterances.push({
          id: `reorg_${Date.now()}_${Math.random().toString(36).slice(2)}`,
          original: item.text,
          translated: targetLang === "none" ? "" : translated,
          timestamp: new Date(),
        })
      }
      
      setUtterances(newUtterances)
      
    } catch (err) {
      console.error("AI ì¬ì •ë¦¬ ì˜¤ë¥˜:", err)
      setError(err instanceof Error ? err.message : "AI ì¬ì •ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
    } finally {
      setIsReorganizing(false)
    }
  }

  // ìš”ì•½ ìƒì„±
  const generateSummary = async () => {
    if (utterances.length === 0) {
      setError("ìš”ì•½í•  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")
      return
    }
    
    setIsSummarizing(true)
    setError(null)
    
    try {
      const fullText = utterances.map(u => u.original).join("\n")
      
      const response = await fetch("/api/gemini/summarize", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          text: fullText,
          language: targetLang === "none" ? (sourceLang === "auto" ? "en" : sourceLang) : targetLang,
        }),
      })
      
      const result = await response.json()
      
      if (!result.success) {
        throw new Error(result.error || "ìš”ì•½ ìƒì„± ì‹¤íŒ¨")
      }
      
      setSummary(result.summary)
      setShowSummary(true)
      
    } catch (err) {
      console.error("ìš”ì•½ ìƒì„± ì˜¤ë¥˜:", err)
      setError(err instanceof Error ? err.message : "ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
    } finally {
      setIsSummarizing(false)
    }
  }

  // DBì— ì €ì¥
  const saveToDatabase = async () => {
    if (utterances.length === 0 || !videoId) {
      setError("ì €ì¥í•  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")
      return
    }
    
    setIsSaving(true)
    setError(null)
    
    try {
      // 1. ì„¸ì…˜ ìƒì„±
      const { data: session, error: sessionError } = await supabase
        .from("sessions")
        .insert({
          source_type: "youtube",
          source_language: sourceLang === "auto" ? "en" : sourceLang,
          target_language: targetLang,
          status: "completed",
          youtube_video_id: videoId,
        })
        .select()
        .single()
      
      if (sessionError) throw sessionError
      
      setSessionId(session.id)
      
      // 2. ë°œí™” ì €ì¥
      for (const utterance of utterances) {
        const { data: utt, error: uttError } = await supabase
          .from("utterances")
          .insert({
            session_id: session.id,
            text: utterance.original,
            source_language: sourceLang === "auto" ? "en" : sourceLang,
          })
          .select()
          .single()
        
        if (uttError) throw uttError
        
        // 3. ë²ˆì—­ ì €ì¥
        if (utterance.translated) {
          await supabase
            .from("translations")
            .insert({
              utterance_id: utt.id,
              text: utterance.translated,
              target_language: targetLang,
            })
        }
      }
      
      // 4. ìš”ì•½ ì €ì¥ (ìˆìœ¼ë©´)
      if (summary) {
        await supabase
          .from("summaries")
          .insert({
            session_id: session.id,
            content: summary,
            language: targetLang === "none" ? (sourceLang === "auto" ? "en" : sourceLang) : targetLang,
          })
      }
      
      setError(null)
      alert("ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
      
    } catch (err) {
      console.error("ì €ì¥ ì˜¤ë¥˜:", err)
      setError("ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
    } finally {
      setIsSaving(false)
    }
  }

  // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
  useEffect(() => {
    return () => {
      stopCapture()
    }
  }, [])

  if (!videoId) {
    return (
      <div className="min-h-screen bg-black flex items-center justify-center text-white">
        <p>YouTube ë¹„ë””ì˜¤ IDê°€ í•„ìš”í•©ë‹ˆë‹¤.</p>
      </div>
    )
  }

  return (
    <div className="min-h-screen bg-slate-900 flex flex-col">
      {/* YouTube ì˜ìƒ ì˜ì—­ */}
      <div className="relative" style={{ height: "55vh" }}>
        <iframe
          src={`https://www.youtube.com/embed/${videoId}?autoplay=1&rel=0`}
          className="absolute inset-0 w-full h-full"
          allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
          allowFullScreen
        />
      </div>

      {/* ì»¨íŠ¸ë¡¤ ë°” */}
      <div className="flex items-center justify-between px-4 py-2 bg-slate-800 border-b border-slate-700">
        <div className="flex items-center gap-3">
          <span className="text-white text-sm font-bold">ğŸŒ UniLang</span>
          {isListening ? (
            <span className="flex items-center gap-1 text-green-400 text-xs">
              <span className="w-2 h-2 bg-green-400 rounded-full animate-pulse" />
              ì‹¤ì‹œê°„ í†µì—­ ì¤‘ (Deepgram)
            </span>
          ) : (
            <span className="text-yellow-400 text-xs">{connectionStatus}</span>
          )}
        </div>
        
        <div className="flex items-center gap-2">
          <span className="text-slate-400 text-xs">
            {LANGUAGES[sourceLang] || sourceLang} â†’ {LANGUAGES[targetLang] || targetLang}
          </span>
          
          {!isReady ? (
            <button
              onClick={startCapture}
              className="px-3 py-1.5 bg-green-500 hover:bg-green-600 text-white text-sm font-medium rounded-lg transition-colors"
            >
              ğŸ§ ì‹œì‘í•˜ê¸°
            </button>
          ) : (
            <button
              onClick={stopCapture}
              className="px-3 py-1.5 bg-red-500 hover:bg-red-600 text-white text-sm font-medium rounded-lg transition-colors"
            >
              â¹ ì¤‘ì§€
            </button>
          )}
        </div>
      </div>

      {/* ì•ˆë‚´ ë©”ì‹œì§€ (ì²˜ìŒì—ë§Œ) */}
      {showInstructions && !isReady && (
        <div className="px-4 py-3 bg-blue-900/50 border-b border-blue-700">
          <p className="text-blue-200 text-sm">
            ğŸ“Œ <strong>ì‚¬ìš©ë²•:</strong> &quot;ì‹œì‘í•˜ê¸°&quot; í´ë¦­ â†’ í™”ë©´ ê³µìœ  ì°½ì—ì„œ <strong>ì´ íƒ­</strong> ì„ íƒ â†’ <strong>&quot;íƒ­ ì˜¤ë””ì˜¤ë„ ê³µìœ &quot;</strong> ì²´í¬ âœ“ â†’ ê³µìœ 
          </p>
        </div>
      )}

      {/* ì—ëŸ¬ ë©”ì‹œì§€ */}
      {error && (
        <div className="px-4 py-2 bg-red-900/50 border-b border-red-700">
          <p className="text-red-300 text-sm whitespace-pre-line">{error}</p>
        </div>
      )}

      {/* ìë§‰ íˆìŠ¤í† ë¦¬ ì˜ì—­ */}
      <div className="flex-1 overflow-y-auto px-4 py-3 space-y-2" style={{ maxHeight: "30vh" }}>
        {utterances.length === 0 ? (
          <p className="text-slate-500 text-center text-sm py-4">
            {isListening 
              ? "ğŸ§ ìŒì„± ì¸ì‹ ì¤‘... YouTube ì˜ìƒì„ ì¬ìƒí•´ì£¼ì„¸ìš”" 
              : "ìœ„ ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ì‹¤ì‹œê°„ í†µì—­ì„ ì‹œì‘í•˜ì„¸ìš”"}
          </p>
        ) : (
          <>
            {utterances.map((utt, idx) => (
              <div key={utt.id} className="bg-slate-800/50 rounded-lg p-3 border border-slate-700">
                <div className="flex items-start gap-2">
                  <span className="text-slate-500 text-xs font-mono">#{idx + 1}</span>
                  <div className="flex-1">
                    <p className="text-white text-sm">{utt.original}</p>
                    {utt.translated && (
                      <p className="text-green-400 text-sm mt-1">{utt.translated}</p>
                    )}
                  </div>
                </div>
              </div>
            ))}
            <div ref={utterancesEndRef} />
          </>
        )}
        
        {/* í˜„ì¬ ì¸ì‹ ì¤‘ì¸ í…ìŠ¤íŠ¸ */}
        {currentTranscript && (
          <div className="bg-yellow-900/30 rounded-lg p-3 border border-yellow-700/50">
            <p className="text-yellow-300 text-sm opacity-70">{currentTranscript}...</p>
          </div>
        )}
      </div>

      {/* í•˜ë‹¨ ì•¡ì…˜ ë°” */}
      {utterances.length > 0 && (
        <div className="px-4 py-3 bg-slate-800 border-t border-slate-700">
          <div className="flex items-center justify-between">
            <span className="text-slate-400 text-xs">
              ì´ {utterances.length}ê°œ ë¬¸ì¥
            </span>
            
            <div className="flex items-center gap-2">
              <button
                onClick={reorganizeWithAI}
                disabled={isReorganizing}
                className="px-3 py-1.5 bg-purple-600 hover:bg-purple-700 disabled:bg-purple-800 disabled:opacity-50 text-white text-xs font-medium rounded-lg transition-colors"
              >
                {isReorganizing ? "ì²˜ë¦¬ ì¤‘..." : "âœ¨ AI ì¬ì •ë¦¬"}
              </button>
              
              <button
                onClick={generateSummary}
                disabled={isSummarizing}
                className="px-3 py-1.5 bg-blue-600 hover:bg-blue-700 disabled:bg-blue-800 disabled:opacity-50 text-white text-xs font-medium rounded-lg transition-colors"
              >
                {isSummarizing ? "ìƒì„± ì¤‘..." : "ğŸ“ ìš”ì•½"}
              </button>
              
              <button
                onClick={saveToDatabase}
                disabled={isSaving}
                className="px-3 py-1.5 bg-teal-600 hover:bg-teal-700 disabled:bg-teal-800 disabled:opacity-50 text-white text-xs font-medium rounded-lg transition-colors"
              >
                {isSaving ? "ì €ì¥ ì¤‘..." : "ğŸ’¾ ì €ì¥"}
              </button>
            </div>
          </div>
        </div>
      )}

      {/* ìš”ì•½ ëª¨ë‹¬ */}
      {showSummary && (
        <div className="fixed inset-0 bg-black/70 flex items-center justify-center z-50 p-4">
          <div className="bg-slate-800 rounded-xl max-w-2xl w-full max-h-[80vh] overflow-y-auto">
            <div className="flex items-center justify-between p-4 border-b border-slate-700">
              <h3 className="text-white font-bold">ğŸ“ ìš”ì•½</h3>
              <button
                onClick={() => setShowSummary(false)}
                className="text-slate-400 hover:text-white"
              >
                âœ•
              </button>
            </div>
            <div className="p-4">
              <p className="text-slate-200 whitespace-pre-wrap">{summary}</p>
            </div>
          </div>
        </div>
      )}
    </div>
  )
}
