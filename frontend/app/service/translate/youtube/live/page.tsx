"use client"

import { useState, useEffect, useRef, Suspense } from "react"
import { useSearchParams } from "next/navigation"

// ì§€ì› ì–¸ì–´ ëª©ë¡
const LANGUAGES: Record<string, string> = {
  "ko": "í•œêµ­ì–´",
  "en": "English",
  "ja": "æ—¥æœ¬èª",
  "zh": "ä¸­æ–‡",
  "es": "EspaÃ±ol",
  "fr": "FranÃ§ais",
  "de": "Deutsch",
  "auto": "ìë™ ê°ì§€",
}

export default function YouTubeLivePage() {
  return (
    <Suspense fallback={<div className="min-h-screen bg-black flex items-center justify-center text-white">ë¡œë”© ì¤‘...</div>}>
      <YouTubeLivePageContent />
    </Suspense>
  )
}

function YouTubeLivePageContent() {
  const searchParams = useSearchParams()
  const videoId = searchParams.get("v")
  const sourceLang = searchParams.get("source") || "auto"
  const targetLang = searchParams.get("target") || "ko"
  
  const [isListening, setIsListening] = useState(false)
  const [currentTranscript, setCurrentTranscript] = useState("")
  const [lastUtterance, setLastUtterance] = useState<{ original: string; translated: string } | null>(null)
  const [error, setError] = useState<string | null>(null)
  const [isReady, setIsReady] = useState(false)
  
  const recognitionRef = useRef<SpeechRecognition | null>(null)
  const isListeningRef = useRef(false)

  // ì–¸ì–´ ì½”ë“œ ë³€í™˜
  const getLanguageCode = (code: string): string => {
    const langMap: Record<string, string> = {
      "ko": "ko-KR",
      "en": "en-US",
      "ja": "ja-JP",
      "zh": "zh-CN",
      "es": "es-ES",
      "fr": "fr-FR",
      "de": "de-DE",
      "auto": "en-US",
    }
    return langMap[code] || "en-US"
  }

  // ë²ˆì—­ í•¨ìˆ˜
  const translateText = async (text: string, from: string, to: string): Promise<string> => {
    if (from === to || to === "none") return text
    
    try {
      const response = await fetch(
        `https://translation.googleapis.com/language/translate/v2?key=${process.env.NEXT_PUBLIC_GOOGLE_API_KEY}`,
        {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({
            q: text,
            source: from === "auto" ? undefined : from,
            target: to,
            format: "text",
          }),
        }
      )
      
      const data = await response.json()
      return data.data?.translations?.[0]?.translatedText || text
    } catch {
      return text
    }
  }

  // ìŒì„± ì¸ì‹ ì´ˆê¸°í™”
  const initRecognition = () => {
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition
    if (!SpeechRecognition) {
      setError("ì´ ë¸Œë¼ìš°ì €ëŠ” ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
      return null
    }

    const recognition = new SpeechRecognition()
    recognition.continuous = true
    recognition.interimResults = true
    recognition.lang = getLanguageCode(sourceLang)
    recognition.maxAlternatives = 3

    let sentenceBuffer = ""
    let silenceTimer: NodeJS.Timeout | null = null
    const SILENCE_THRESHOLD = 1500

    recognition.onresult = async (event) => {
      let interimTranscript = ""
      let finalTranscript = ""

      for (let i = event.resultIndex; i < event.results.length; i++) {
        const result = event.results[i]
        const transcript = result[0].transcript
        const confidence = result[0].confidence
        
        if (result.isFinal) {
          if (confidence === undefined || confidence >= 0.5) {
            finalTranscript += transcript
          }
        } else {
          interimTranscript += transcript
        }
      }

      setCurrentTranscript(interimTranscript)

      if (finalTranscript.trim()) {
        sentenceBuffer += (sentenceBuffer ? " " : "") + finalTranscript.trim()
        
        if (silenceTimer) clearTimeout(silenceTimer)
        
        if (/[.!?ã€‚ï¼ï¼Ÿ]$/.test(sentenceBuffer.trim())) {
          await processUtterance(sentenceBuffer.trim())
          sentenceBuffer = ""
          setCurrentTranscript("")
        } else {
          silenceTimer = setTimeout(async () => {
            if (sentenceBuffer.trim()) {
              await processUtterance(sentenceBuffer.trim())
              sentenceBuffer = ""
              setCurrentTranscript("")
            }
          }, SILENCE_THRESHOLD)
        }
      }
    }

    recognition.onerror = (event) => {
      console.error("ìŒì„± ì¸ì‹ ì˜¤ë¥˜:", event.error)
      if ((event.error === "no-speech" || event.error === "audio-capture") && isListeningRef.current) {
        try {
          recognition.stop()
          setTimeout(() => {
            if (isListeningRef.current) {
              recognition.start()
            }
          }, 100)
        } catch {}
      }
    }

    recognition.onend = () => {
      if (sentenceBuffer.trim()) {
        processUtterance(sentenceBuffer.trim())
        sentenceBuffer = ""
      }
      if (silenceTimer) clearTimeout(silenceTimer)
      
      if (isListeningRef.current) {
        try {
          recognition.start()
        } catch {}
      }
    }

    return recognition
  }

  // ë°œí™” ì²˜ë¦¬ (ë²ˆì—­ í¬í•¨)
  const processUtterance = async (text: string) => {
    const srcLang = sourceLang === "auto" ? "en" : sourceLang
    let translated = ""
    
    try {
      if (targetLang !== "none" && targetLang !== srcLang) {
        translated = await translateText(text, srcLang, targetLang)
      }
    } catch (err) {
      console.error("ë²ˆì—­ ì‹¤íŒ¨:", err)
    }
    
    setLastUtterance({ original: text, translated })
  }

  // ì‹œìŠ¤í…œ ì˜¤ë””ì˜¤ ìº¡ì²˜ + ìŒì„± ì¸ì‹ ì‹œì‘
  const startCapture = async () => {
    try {
      setError(null)
      
      // í™”ë©´ ê³µìœ ë¡œ ì‹œìŠ¤í…œ ì˜¤ë””ì˜¤ ìº¡ì²˜
      const stream = await navigator.mediaDevices.getDisplayMedia({
        video: true,
        audio: {
          echoCancellation: false,
          noiseSuppression: false,
          autoGainControl: false,
        }
      })

      const audioTracks = stream.getAudioTracks()
      if (audioTracks.length === 0) {
        setError("ì˜¤ë””ì˜¤ ê³µìœ ë¥¼ ì²´í¬í•´ì£¼ì„¸ìš”!")
        stream.getTracks().forEach(track => track.stop())
        return
      }

      // ë¹„ë””ì˜¤ íŠ¸ë™ ì¤‘ì§€
      stream.getVideoTracks().forEach(track => track.stop())
      
      // ìŒì„± ì¸ì‹ ì‹œì‘
      const recognition = initRecognition()
      if (recognition) {
        recognitionRef.current = recognition
        isListeningRef.current = true
        setIsListening(true)
        recognition.start()
      }

      // ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ ê°ì§€
      audioTracks[0].onended = () => {
        stopCapture()
      }

      setIsReady(true)
      
    } catch (err) {
      if ((err as Error).name === "NotAllowedError") {
        setError("í™”ë©´ ê³µìœ ê°€ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
      } else {
        setError("ì‹œìŠ¤í…œ ì˜¤ë””ì˜¤ ìº¡ì²˜ ì‹¤íŒ¨")
      }
    }
  }

  // ìº¡ì²˜ ì¤‘ì§€
  const stopCapture = () => {
    if (recognitionRef.current) {
      isListeningRef.current = false
      recognitionRef.current.stop()
      setIsListening(false)
    }
    setIsReady(false)
  }

  // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
  useEffect(() => {
    return () => {
      if (recognitionRef.current) {
        isListeningRef.current = false
        recognitionRef.current.stop()
      }
    }
  }, [])

  // ìë™ ì‹œì‘ (í˜ì´ì§€ ë¡œë“œ ì‹œ)
  useEffect(() => {
    if (videoId) {
      // ì•½ê°„ì˜ ë”œë ˆì´ í›„ ìë™ ì‹œì‘
      const timer = setTimeout(() => {
        startCapture()
      }, 1000)
      return () => clearTimeout(timer)
    }
  }, [videoId])

  if (!videoId) {
    return (
      <div className="min-h-screen bg-black flex items-center justify-center text-white">
        <p>YouTube ë¹„ë””ì˜¤ IDê°€ í•„ìš”í•©ë‹ˆë‹¤.</p>
      </div>
    )
  }

  return (
    <div className="min-h-screen bg-black flex flex-col">
      {/* YouTube ì˜ìƒ - ì „ì²´ í™”ë©´ */}
      <div className="flex-1 relative">
        <iframe
          src={`https://www.youtube.com/embed/${videoId}?autoplay=1&rel=0`}
          className="absolute inset-0 w-full h-full"
          allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
          allowFullScreen
        />
      </div>

      {/* ìë§‰ ì˜¤ë²„ë ˆì´ - í•˜ë‹¨ ê³ ì • */}
      <div className="fixed bottom-0 left-0 right-0 z-50">
        {/* ìƒíƒœ í‘œì‹œ ë°” */}
        <div className="flex items-center justify-between px-4 py-2 bg-black/70">
          <div className="flex items-center gap-3">
            <span className="text-white text-sm font-medium">UniLang</span>
            {isListening ? (
              <span className="flex items-center gap-1 text-green-400 text-xs">
                <span className="w-2 h-2 bg-green-400 rounded-full animate-pulse" />
                ì‹¤ì‹œê°„ í†µì—­ ì¤‘
              </span>
            ) : (
              <span className="text-yellow-400 text-xs">ëŒ€ê¸° ì¤‘</span>
            )}
          </div>
          <div className="flex items-center gap-2">
            <span className="text-slate-400 text-xs">
              {LANGUAGES[sourceLang] || sourceLang} â†’ {LANGUAGES[targetLang] || targetLang}
            </span>
            {!isReady && (
              <button
                onClick={startCapture}
                className="px-3 py-1 bg-green-500 hover:bg-green-600 text-white text-xs rounded-full"
              >
                ì‹œì‘
              </button>
            )}
            {isReady && (
              <button
                onClick={stopCapture}
                className="px-3 py-1 bg-red-500 hover:bg-red-600 text-white text-xs rounded-full"
              >
                ì¤‘ì§€
              </button>
            )}
          </div>
        </div>

        {/* ìë§‰ ì˜ì—­ */}
        <div className="px-4 py-3 bg-black/85 min-h-[80px]">
          {error ? (
            <p className="text-red-400 text-center text-sm">{error}</p>
          ) : (
            <>
              {/* í˜„ì¬ ì¸ì‹ ì¤‘ì¸ í…ìŠ¤íŠ¸ */}
              {currentTranscript && (
                <p className="text-yellow-300 text-center text-lg mb-2 opacity-70">
                  {currentTranscript}...
                </p>
              )}
              
              {/* ìµœì¢… ìë§‰ */}
              {lastUtterance ? (
                <div className="text-center space-y-1">
                  <p className="text-white text-xl font-medium drop-shadow-lg">
                    {lastUtterance.original}
                  </p>
                  {lastUtterance.translated && (
                    <p className="text-green-400 text-xl font-medium drop-shadow-lg">
                      {lastUtterance.translated}
                    </p>
                  )}
                </div>
              ) : (
                <p className="text-slate-500 text-center text-sm">
                  {isListening ? "ğŸ¤ ìŒì„±ì„ ê¸°ë‹¤ë¦¬ëŠ” ì¤‘..." : "ì‹œì‘ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”"}
                </p>
              )}
            </>
          )}
        </div>
      </div>
    </div>
  )
}

